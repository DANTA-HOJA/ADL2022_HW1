import json
import pickle
from argparse import ArgumentParser, Namespace
from pathlib import Path
from typing import Dict

import os
import time

from tqdm import tqdm
from tqdm import trange
import matplotlib.pyplot as plt

import torch
from torch.utils.data import DataLoader
import torch.optim as optim
from torch import nn

from utils import Vocab
from model import IntentCls_RNN, IntentCls_LSTM
from dataset import IntentClsDataset

TAG_DATASET = ["train", "eval"]

def main(args):
    with open(args.cache_dir / "vocab.pkl", "rb") as f:
        vocab: Vocab = pickle.load(f) # Vocab(common_words)

    intent2idx_json = args.cache_dir / "intent2idx.json"
    intent2idx: Dict[str, int] = json.loads(intent2idx_json.read_text())

    data_paths = {tag: args.data_dir / f"{tag}.json" for tag in TAG_DATASET}
    # print(data_paths) # {'train': PosixPath('data/intent/train.json'), 'eval': PosixPath('data/intent/eval.json')}

    train_set = IntentClsDataset(data_paths["train"], vocab, intent2idx, args.max_len)
    eval_set = IntentClsDataset(data_paths["eval"], vocab, intent2idx, args.max_len)
    print(f"\nData in train_set = {train_set.__len__()}, Data in eval_set = {eval_set.__len__()}")
    # CHECK_PT: 
    input("\n=> press Enter to continue")
    
    # DO: crecate DataLoader for train / dev datasets
    dataloaders = {
        'train': DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4),
        'eval': DataLoader(eval_set, batch_size=args.batch_size, shuffle=True, num_workers=4)
    }
    print(f"\ndataloaders = {dataloaders}")
    # CHECK_PT: 
    input("\n=> press Enter to continue\n") 
    
    # DO: check if CUDA is available
    if not torch.cuda.is_available():
        print("QQ, you should buy a graphic card ~, device chang to 'cpu'\n")
        args.device = "cpu"
    device = torch.device(args.device)
    print(f'==> device using {device}')
    
    # DO: load embedding
    embeddings = torch.load(args.cache_dir / "embeddings.pt")
    embeddings = embeddings.to(device)
    
    # DO: init model
    model = IntentCls_LSTM(embeddings=embeddings, hidden_size=args.hidden_size, num_layers=args.num_layers,
                          dropout= args.dropout, bidirectional= args.bidirectional,
                          num_classes=train_set.num_classes, device=device) # init model
    model = model.to(device) # send model to device
    print(model)
    
    # DO: init optimizer, and loss_function
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    loss_fn = nn.CrossEntropyLoss()
    
    # DO: add some parameters
    best_weight_ckpt = args.ckpt_dir / f"{model.MODEL_TYPE()}_best_weight.ckpt" # where to save file
    best_loss = 1e10
    batch_acc = 0
    
    epoch_pbar = trange(args.num_epoch, desc=f"Epoch: ACC({batch_acc:.4%})")
    for epoch in epoch_pbar:
        
        # DO: add some parameters
        Dataset_loss_logger = {'train': [], 'eval': []} # logger
        epoch_t_start = time.time() # save start time for a new epoch
        epoch_pbar.desc = f"Epoch: ACC({batch_acc:.4%})"
        
        # # TODO: Training loop - iterate over train dataloader and update model weights
        
        # # DO: add some parameters
        # train_batch_loss = 0 # loss of current batch
        # train_cum_loss = 0 # accumulation_loss of all batches
        # num_train_batch = 0 # how many batches are generated by dataloader with train_set
        # train_avg_loss = 0 # train_avg_loss = train_cum_loss/num_train_batch
        
        # model.train()
        # batch_bar = tqdm(dataloaders["train"], desc="Train")
        # for batch_index, data in enumerate(batch_bar): # Each time, take [# = batch_size] of data
            
        #     # DO: unpackage the data and sent to CPU/GPU
        #     sentence, intent = data # sentence.shape = [batch_size, sentence_max_len]
        #                             # intent.shape = [batch_size, 1]
        #     sentence, intent = sentence.to(device), intent.to(device)
        #     tqdm.write(f"sentence.shape = {sentence.shape}, intent.shape = {intent.shape}")
        #     # CHECK_PT: 
        #     input("\n=> press Enter to continue")
            
        #     # DO: train with this batch, and get prediction
        #     pred = model(sentence) # return softmax(IntentCls_RNN) or logsoftmax(IntentCls_LSTM) for each class
        #                            # pred.shape = [batch_size, intent_classes]
        #     loss = loss_fn(pred, intent) # loss_fn(para:softmax_prob, para:intent_in_index)
        #     # CHECK_PT:
        #     input("\n=> press Enter to continue")
            
        #     # DO: update the gradient using backpropagation
        #     optimizer.zero_grad() # zero the parameter of gradients before backpropagation
        #     loss.backward() # use loss to do backpropagation
        #     optimizer.step() # update the optimizer with gradient
        
        
        # # TODO: Evaluation loop - calculate accuracy and save model weights
        
        
        
        
        # DO: Each epoch has a training and validation phase
        for TAG in TAG_DATASET:
            
            # DO: add some parameters
            Dataset_loss = 0
            num_batches = 0 # how many batches are generated by dataloader
            
            # DO: set model mode
            if TAG == "train":
                model.train()
            else:
                model.eval()
            
            # DO: Start the training process through all batches
            batch_bar = tqdm(dataloaders[TAG], desc=TAG)
            for batch_index, data in enumerate(batch_bar):
                sentence, intent = data
                sentence, intent = sentence.to(device), intent.to(device)

                # forward
                torch.set_grad_enabled(False)
                with torch.set_grad_enabled(TAG == "train"): 
                    pred = model(sentence)# return softmax(IntentCls_RNN) or logsoftmax(IntentCls_LSTM) for each class
                                          # pred.shape = [batch_size, intent_classes]
                    batch_loss = loss_fn(pred, intent) # loss_fn(para:softmax_prob, para:intent_in_index)
                    
                    # DO: (train only) update the gradient using backpropagation 
                    if TAG == "train":
                        optimizer.zero_grad() # zero the parameter of gradients before backpropagation
                        batch_loss.backward() # use loss to do backpropagation
                        optimizer.step() # update the optimizer with gradient
                    
                    # DO: update batch_Info to CMD
                    tqdm.write(f"{TAG}: batch_index = {batch_index}, metrics : batch_loss = {batch_loss}")
                    Dataset_loss += batch_loss.detach().cpu().numpy()
                    
                    if TAG == "eval":
                        correct = 0
                        # DO: calculate match item
                        for i in range(len(pred)):
                            _, pred_cls = torch.max(pred[i],0) # return ["highest probability value" in pred], [index of "highest probability value" in pred]==predicted_intent_class
                            groundtruth_cls = intent[i]
                            if pred_cls == groundtruth_cls: correct+=1
                        batch_acc = (correct/intent.shape[0])
                        tqdm.write(f"{TAG}: correct = {correct}, intent.shape[0] = {intent.shape[0]}, batch_acc = {batch_acc}")
                        tqdm.write(f"{TAG}: batch_index = {batch_index}, metrics : batch_accuracy = {batch_acc:.4%}, batch_loss = {batch_loss}")
                        
                num_batches += 1
            # end : batch
            os.system("clear")
            
            # DO: calculate the avg_loss in Train/eval Dataset, and add the value to logger
            avg_Dataset_loss = Dataset_loss/num_batches
            Dataset_loss_logger[TAG].append(avg_Dataset_loss)
            tqdm.write(f"number of batches = {num_batches}, avg_Dataset_loss = {avg_Dataset_loss}")
            # CHECK_PT: 
            # input(f"\n=> end of {TAG}, press Enter to continue")

            # DO: save the best model info
            if TAG == 'eval' and avg_Dataset_loss < best_loss:
                if avg_Dataset_loss < best_loss:
                    tqdm.write(f"saving best model to {best_weight_ckpt}")
                    best_loss = avg_Dataset_loss
                    torch.save({
                                'model_state_dict': model.state_dict(),
                                'optimizer_state_dict': optimizer.state_dict(),
                                'trian_loss': Dataset_loss_logger['train'],
                                'eval_loss' : Dataset_loss_logger['eval']
                                }, best_weight_ckpt)  
        
        
        # DO: calculate the consuming time of this epoch
        epoch_t_stop = time.time() # update the stop time for this epoch
        cost_min = (epoch_t_stop - epoch_t_start) / 60 
        cost_sec = (epoch_t_stop - epoch_t_start) % 60
        
        # DO: update Info to CMD
        tqdm.write(f"epoch = {epoch}, time_cost = {cost_min:.0f}m {cost_sec:.0f}s, accuracy = {batch_acc:.4%}, best_loss = {best_loss}")

        # logs graph
        if epoch%10 == 0:
            plt.plot(Dataset_loss_logger['train'])
            plt.plot(Dataset_loss_logger['eval'])
            plt.legend(['train', 'eval'])
            plt.title('loss')
            plt.show()

    # TODO: Inference on test set


def parse_args() -> Namespace:
    parser = ArgumentParser()
    parser.add_argument(
        "--data_dir",
        type=Path,
        help="Directory to the dataset.",
        default="./data/intent/",
    )
    parser.add_argument(
        "--cache_dir",
        type=Path,
        help="Directory to the preprocessed caches.",
        default="./cache/intent/",
    )
    parser.add_argument(
        "--ckpt_dir",
        type=Path,
        help="Directory to save the model file.",
        default="./ckpt/intent/",
    )

    # data
    parser.add_argument("--max_len", type=int, default=128)

    # model
    parser.add_argument("--hidden_size", type=int, default=512)
    parser.add_argument("--num_layers", type=int, default=2)
    parser.add_argument("--dropout", type=float, default=0.1)
    parser.add_argument("--bidirectional", type=bool, default=True)

    # optimizer
    parser.add_argument("--lr", type=float, default=1e-3)

    # data loader
    parser.add_argument("--batch_size", type=int, default=256)

    # training
    parser.add_argument(
        "--device", type=str, help="cpu, cuda, cuda:0, cuda:1", default="cuda:0"
    )
    parser.add_argument("--num_epoch", type=int, default=100)

    args = parser.parse_args()
    return args


if __name__ == "__main__":
    args = parse_args()
    args.ckpt_dir.mkdir(parents=True, exist_ok=True)
    main(args)
