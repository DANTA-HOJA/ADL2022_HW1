{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "from utils import Vocab\n",
    "from model import IntentCls_RNN, IntentCls_LSTM\n",
    "from dataset import IntentClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_DATASET = [\"train\", \"eval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # file\n",
    "        self.data_dir : Path = Path(\"./data/intent/\")\n",
    "        self.cache_dir : Path = Path(\"./cache/intent/\")\n",
    "        self.ckpt_dir : Path = Path(\"./ckpt/intent/\")\n",
    "        \n",
    "        # data\n",
    "        self.max_len : int = 128\n",
    "        \n",
    "        # model\n",
    "        self.hidden_size : int = 512\n",
    "        self.num_layers : int = 2\n",
    "        self.dropout : int = 0.1\n",
    "        self.bidirectional : int = True\n",
    "        \n",
    "        # optimizer\n",
    "        self.lr : float = 1e-3\n",
    "        \n",
    "        # data loader\n",
    "        self.batch_size : int = 256\n",
    "        \n",
    "        # training\n",
    "        self.device : str = \"cuda:1\"\n",
    "        self.num_epoch : int = 100\n",
    "        \n",
    "args = args() # init training parameter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.device == \"cpu\":\n",
    "    print(\"QQ, you should use a graphic card ~, if you don't have it, just buy it\")\n",
    "else:\n",
    "    try:\n",
    "        gpu_name = torch.cuda.get_device_name(args.device)\n",
    "    except Exception as e:\n",
    "        print(\"*\"*100)\n",
    "        print(f\"device {args.device} not found, {e.__class__.__name__}: {e.args[0]}\\n\") # get detail Error_Info\n",
    "        if torch.cuda.is_available(): \n",
    "            args.device = torch.cuda.current_device()\n",
    "            print(f\"==> find one available gpu at cuda:{args.device}\")\n",
    "            gpu_name = torch.cuda.get_device_name(args.device)\n",
    "        else:\n",
    "            args.device = \"cpu\"\n",
    "            print(\"as you know, you don't have a graphic card, stop dreaming ~\")\n",
    "        print(\"*\"*100)\n",
    "    print(f\"\\nhi, i am '{gpu_name}' ~\")\n",
    "device = torch.device(args.device)\n",
    "print(f\"==> device using {device}\\n\")\n",
    "# DO: clean GPU cache\n",
    "if args.device != \"cpu\":\n",
    "    torch.cuda.empty_cache() \n",
    "    print(\"torch.cuda.empty_cache()\")\n",
    "# CHECK_PT: device setting complete\n",
    "# input(\"\\n=> device setting complete, press Enter to continue\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: Load file create by \"preprocess_intent.py\" ==> vocab, intent2idx, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.cache_dir / \"vocab.pkl\", \"rb\") as f:\n",
    "    vocab: Vocab = pickle.load(f) # Vocab(common_words)\n",
    "\n",
    "intent2idx_json = args.cache_dir / \"intent2idx.json\"\n",
    "intent2idx: Dict[str, int] = json.loads(intent2idx_json.read_text())\n",
    "\n",
    "embeddings = torch.load(args.cache_dir / \"embeddings.pt\")\n",
    "embeddings = embeddings.to(device)\n",
    "\n",
    "print(type(vocab), type(intent2idx), type(embeddings))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: Load train and evaluation data for training and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {tag: args.data_dir / f\"{tag}.json\" for tag in TAG_DATASET}\n",
    "# print(data_paths) # output => {'train': PosixPath('data/intent/train.json'), 'eval': PosixPath('data/intent/eval.json')}\n",
    "\n",
    "train_set = IntentClsDataset(data_paths[\"train\"], vocab, intent2idx, args.max_len)\n",
    "eval_set = IntentClsDataset(data_paths[\"eval\"], vocab, intent2idx, args.max_len)\n",
    "print(f\"\\nData in train_set = {train_set.__len__()}, Data in eval_set = {eval_set.__len__()}\\n\")\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4),\n",
    "    'eval': DataLoader(eval_set, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
    "}\n",
    "print(f\"dataloaders = {dataloaders}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntentCls_LSTM(embeddings=embeddings, hidden_size=args.hidden_size, num_layers=args.num_layers,\n",
    "                        dropout= args.dropout, bidirectional= args.bidirectional,\n",
    "                        num_classes=train_set.num_classes, device=device) # init model\n",
    "model = model.to(device) # send model to device\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: init optimizer, and loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"optimizer = {optimizer}\\n\")\n",
    "print(f\"loss_fn = {loss_fn}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: add some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch_loss_logger = {'train': [], 'eval': []} # loss logger\n",
    "Epoch_acc_logger = {'train': [], 'eval': []} # acc logger\n",
    "best_avg_loss = 1e10\n",
    "best_avg_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO: Start Training\n",
    "epoch_pbar = trange(args.num_epoch)\n",
    "for epoch in epoch_pbar:\n",
    "\n",
    "    # DO: add some parameters\n",
    "    epoch_weight_ckpt = args.ckpt_dir / f\"{model.MODEL_TYPE()}_best_weight.ckpt\" # where to save epoch weight file => training recovery\n",
    "    \n",
    "    epoch_t_start = time.time() # save start time for a new epoch\n",
    "    epoch_pbar.desc = f\"Epoch: {epoch}, BEST_ACC({best_avg_acc:.2%})\"\n",
    "    \n",
    "    # DO: Epoch start, one epoch = training + evaluation through all batches\n",
    "    for TAG in TAG_DATASET:\n",
    "        \n",
    "        # DO: add some parameters\n",
    "        num_batches = 0 # how many batches are generated by dataloader\n",
    "        # Parameters: loss\n",
    "        batch_loss = 0 # loss of current batch\n",
    "        batch_cum_loss = 0 # an accumulation of loss of all batches\n",
    "        avg_batch_loss = 0 # avg_batch_loss = batch_cum_loss/num_batches\n",
    "        # Parameters: accuracy\n",
    "        batch_acc = 0 \n",
    "        batch_cum_acc = 0\n",
    "        avg_batch_acc = 0\n",
    "        \n",
    "        # DO: set model mode\n",
    "        if TAG == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        # DO: Start the train or evaluate process through all batches\n",
    "        batch_bar = tqdm(dataloaders[TAG])\n",
    "        for batch_index, data in enumerate(batch_bar):\n",
    "            sentence, intent = data # sentence.shape = [batch_size, sentence_max_len]\n",
    "                                    # intent.shape = [batch_size, 1]             \n",
    "            sentence, intent = sentence.to(device), intent.to(device)\n",
    "\n",
    "            torch.set_grad_enabled(False)\n",
    "            with torch.set_grad_enabled(TAG == \"train\"): \n",
    "                # DO: predict, calculate loss of this batch, and accumulate the loss\n",
    "                pred = model(sentence)# return softmax(IntentCls_RNN) or logsoftmax(IntentCls_LSTM) for each class\n",
    "                                        # pred.shape = [batch_size, intent_classes]\n",
    "                batch_loss = loss_fn(pred, intent) # loss_fn(para:softmax_prob, para:intent_in_index)\n",
    "                batch_cum_loss += batch_loss.detach().cpu().numpy() # tensor.detach().cpu().numpy() => copy data from GPU to CPU\n",
    "                \n",
    "                # DO (train only): update the gradient using backpropagation\n",
    "                if TAG == \"train\":\n",
    "                    optimizer.zero_grad() # zero the parameter of gradients before backpropagation\n",
    "                    batch_loss.backward() # use loss to do backpropagation\n",
    "                    optimizer.step() # update the optimizer with gradient computed in backpropagation\n",
    "                \n",
    "                # DO: calculate accuracy of this batch, and accumulate the accuracy\n",
    "                correct = 0\n",
    "                total = intent.shape[0]\n",
    "                for i in range(len(pred)): # calculate match item\n",
    "                    _, pred_cls = torch.max(pred[i],0) # return [\"highest probability value\" in pred], [index of \"highest probability value\" in pred]==predicted_intent_class\n",
    "                    groundtruth_cls = intent[i]\n",
    "                    if pred_cls == groundtruth_cls: correct+=1\n",
    "                batch_acc = correct / total\n",
    "                batch_cum_acc += batch_acc\n",
    "                \n",
    "                # DO: update batch_Info to CMD\n",
    "                # batch_bar.write(f\"{TAG}: batch_index = {batch_index}, metrics : batch_accuracy = {batch_acc:.2%} ({correct}/{total}), batch_loss = {batch_loss}\")\n",
    "            \n",
    "            # CHECK_PT: one batch process complete\n",
    "            # input(f\"\\n=> one {TAG} batch process complete, batch_index = {batch_index}, press Enter to continue\")\n",
    "            num_batches += 1\n",
    "        # end : batch\n",
    "        \n",
    "        # DO: calculate the \"average loss\" in \"train/eval set\", and add to logger\n",
    "        avg_batch_loss = batch_cum_loss/num_batches\n",
    "        #print(type(avg_batch_loss), type(Epoch_loss_logger[TAG]))\n",
    "        Epoch_loss_logger[TAG].append(avg_batch_loss)\n",
    "        \n",
    "        # DO: calculate the \"average accuracy\" in \"train/eval set\", and add to logger\n",
    "        avg_batch_acc = batch_cum_acc/num_batches\n",
    "        #print(type(avg_batch_loss), type(Epoch_loss_logger[TAG]))\n",
    "        Epoch_acc_logger[TAG].append(avg_batch_acc)\n",
    "        \n",
    "        # DO: update Info to CMD\n",
    "        epoch_pbar.write(f\"Epoch_loss_logger: train_len = {len(Epoch_loss_logger['train'])}, eval_len = {len(Epoch_loss_logger['eval'])}\")\n",
    "        epoch_pbar.write(\"=\"*100)\n",
    "        epoch_pbar.write(\"\") # # write empty new_line\n",
    "        epoch_pbar.write(f\"{TAG}: number of batches = {num_batches}, avg_batch_acc = {avg_batch_acc:.2%}, avg_batch_loss = {avg_batch_loss}\")\n",
    "\n",
    "        # DO: save the best model info\n",
    "        if TAG == 'eval' and avg_batch_loss < best_avg_loss and avg_batch_acc > best_avg_acc:\n",
    "            best_avg_loss = avg_batch_loss\n",
    "            best_avg_acc = avg_batch_acc\n",
    "            best_weight_ckpt = args.ckpt_dir / f\"{model.MODEL_TYPE()}_best_weight.ckpt\" # where to save best weight file\n",
    "            epoch_pbar.write(f\"\\nsaving best model to {best_weight_ckpt}\\n\")\n",
    "            torch.save({\n",
    "                        # Info: model_state_dict, optimizer_state_dict(discard)\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        #'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        # Info: Epoch_loss_logger, best_avg_loss\n",
    "                        'trian_loss': Epoch_loss_logger['train'],\n",
    "                        'eval_loss' : Epoch_loss_logger['eval'],\n",
    "                        'best_avg_loss': best_avg_loss,\n",
    "                        # Info: Epoch_acc_logger, best_avg_acc\n",
    "                        'trian_acc': Epoch_acc_logger['train'],\n",
    "                        'eval_acc' : Epoch_acc_logger['eval'],\n",
    "                        'best_avg_acc': best_avg_acc,\n",
    "                        # Info: epoch, total_epoch(manual)\n",
    "                        'epoch': [epoch+1, args.num_epoch],\n",
    "                        'model_para':{\n",
    "                            'hidden_size' : args.hidden_size,\n",
    "                            'num_layers' : args.num_layers,\n",
    "                            'dropout' : args.dropout,\n",
    "                            'bidirectional' : args.bidirectional,\n",
    "                            'num_classes' : train_set.num_classes\n",
    "                            }\n",
    "                        }, best_weight_ckpt)\n",
    "        \n",
    "        # CHECK_PT: all batches process complete\n",
    "        # input(f\"\\n=> all {TAG} batches process complete, press Enter to continue\")\n",
    "    # end : epoch\n",
    "    \n",
    "    # DO: calculate the consuming time of this epoch\n",
    "    epoch_t_stop = time.time() # update the stop time for this epoch\n",
    "    cost_min = (epoch_t_stop - epoch_t_start) / 60 \n",
    "    cost_sec = (epoch_t_stop - epoch_t_start) % 60\n",
    "    \n",
    "    # DO: update Info to CMD\n",
    "    epoch_pbar.write(f\"epoch = {epoch}, time_cost = {math.floor(cost_min):.0f} m {math.floor(cost_sec):.0f} s, best_avg_acc = {best_avg_acc:.2%}, best_avg_loss = {best_avg_loss}\")\n",
    "    epoch_pbar.write(\"\") # write empty new_line\n",
    "    epoch_pbar.write(\"=\"*100)\n",
    "      \n",
    "    # CHECK_PT: one epoch process complete\n",
    "    # input(f\"\\n=> one epoch process complete, press Enter to continue\")\n",
    "# CHECK_PT: all epochs process complete\n",
    "# input(f\"\\n=> all epochs process complete, press Enter to continue\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: plot and save \"Epoch_loss\" and \"Epoch_acc\" graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO: plot and save \"Epoch_loss\" graph\n",
    "plt.figure(\"Epoch_loss\")\n",
    "plt.plot(Epoch_loss_logger['train'])\n",
    "plt.plot(Epoch_loss_logger['eval'])\n",
    "plt.legend(['train', 'eval'])\n",
    "plt.savefig(\"epoch_Loss_logger.png\")\n",
    "# DO: plot and save \"Epoch_acc\" graph\n",
    "plt.figure(\"Epoch_acc\")\n",
    "plt.plot(Epoch_acc_logger['train'])\n",
    "plt.plot(Epoch_acc_logger['eval'])\n",
    "plt.legend(['train', 'eval'])\n",
    "plt.savefig(\"epoch_Acc_logger.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO: release GPU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.device != \"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"torch.cuda.empty_cache()\")\n",
    "# CHECK_PT: release GPU cache complete\n",
    "# input(f\"\\n=> release GPU cache complete, press Enter to continue\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
